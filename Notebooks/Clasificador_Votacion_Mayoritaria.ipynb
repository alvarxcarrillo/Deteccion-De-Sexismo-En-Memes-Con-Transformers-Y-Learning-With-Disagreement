{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["pQECP4q5SdPG","JhzEpPNUT423","vJ0309b8aQWE","2KLQvEtGawss","dIRbkpOCbt-P","wOEspzUOcG1Y"],"authorship_tag":"ABX9TyOxVNEt6vZz+5Pjz2h2GkSE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# CLASIFICADOR DE TEXTO MEDIANTE VOTACION MAYORITARIA"],"metadata":{"id":"kEkOKNbjSVfx"}},{"cell_type":"markdown","source":["## Importar Dependencias y Librerias"],"metadata":{"id":"pQECP4q5SdPG"}},{"cell_type":"code","source":["# Instalacion de dependencias\n","!pip install pytorch-lightning\n","!pip install --upgrade accelerate\n","!pip install framework-reproducibility\n","!pip install transformers datasets\n","!pip install --upgrade numpy\n","!pip install --upgrade pandas\n","!pip install --upgrade scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rqI4xWNDScR9","executionInfo":{"status":"ok","timestamp":1718814828631,"user_tz":-120,"elapsed":182506,"user":{"displayName":"Alvaro Carrillo","userId":"09121382412307725613"}},"outputId":"4dd55a48-69de-4838-a12e-45c751987132"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.3.0-py3-none-any.whl (812 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.2/812.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.25.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.3.0+cu121)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.4)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n","Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n","Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.1)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\n","Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2.31.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (67.7.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (3.14.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0.0->pytorch-lightning)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0.0->pytorch-lightning)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0.0->pytorch-lightning)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.0.0->pytorch-lightning)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0.0->pytorch-lightning)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0.0->pytorch-lightning)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0.0->pytorch-lightning)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0.0->pytorch-lightning)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0.0->pytorch-lightning)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.0.0->pytorch-lightning)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0.0->pytorch-lightning)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->pytorch-lightning)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->pytorch-lightning) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->pytorch-lightning) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n","Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pytorch-lightning-2.3.0 torchmetrics-1.4.0.post0\n","Collecting accelerate\n","  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.31.0\n","Collecting framework-reproducibility\n","  Downloading framework_reproducibility-0.6.0-py2.py3-none-any.whl (19 kB)\n","Installing collected packages: framework-reproducibility\n","Successfully installed framework-reproducibility-0.6.0\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Collecting datasets\n","  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Collecting requests (from transformers)\n","  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Collecting numpy\n","  Downloading numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","astropy 5.3.4 requires numpy<2,>=1.21, but you have numpy 2.0.0 which is incompatible.\n","cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 2.0.0 which is incompatible.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.0.0 which is incompatible.\n","ibis-framework 8.0.0 requires numpy<2,>=1, but you have numpy 2.0.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\n","numba 0.58.1 requires numpy<1.27,>=1.22, but you have numpy 2.0.0 which is incompatible.\n","rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 2.0.0 which is incompatible.\n","scipy 1.11.4 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.0.0 which is incompatible.\n","tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-2.0.0\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Collecting pandas\n","  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.0.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Installing collected packages: pandas\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.0.3\n","    Uninstalling pandas-2.0.3:\n","      Successfully uninstalled pandas-2.0.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 2.0.0 which is incompatible.\n","cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.2.2 which is incompatible.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n","ibis-framework 8.0.0 requires numpy<2,>=1, but you have numpy 2.0.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pandas-2.2.2\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Collecting scikit-learn\n","  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (2.0.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Collecting numpy>=1.19.5 (from scikit-learn)\n","  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, scikit-learn\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.0\n","    Uninstalling numpy-2.0.0:\n","      Successfully uninstalled numpy-2.0.0\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.4 scikit-learn-1.5.0\n"]}]},{"cell_type":"markdown","source":["Reiniciar Entorno (Recomendable de hacer siempre despues de instalar dependencias)"],"metadata":{"id":"_XEeFKV0Swu6"}},{"cell_type":"code","source":["# Instalacion de librerias\n","import random\n","import torch\n","import numpy as np\n","import os\n","from pytorch_lightning import seed_everything\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)# Store the average loss after eachepoch so we can plot them.\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\" # See:https://github.com/NVIDIA/tensorflow-determinism#confirmed-current-gpu-specific-sources-of-non-determinism-with-solutions\n","seed_everything(42, workers=True)\n","\n","from datasets import Dataset, DatasetDict, load_metric\n","import pandas as pd\n","import sklearn as sk\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score, f1_score\n","from sklearn.model_selection import train_test_split\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, \\\n","TrainingArguments, Trainer, pipeline, EarlyStoppingCallback"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Vzvy6HlS6ai","executionInfo":{"status":"ok","timestamp":1718814916594,"user_tz":-120,"elapsed":25701,"user":{"displayName":"Alvaro Carrillo","userId":"09121382412307725613"}},"outputId":"39516b8c-258e-4d90-8b18-09097dd04c2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:lightning_fabric.utilities.seed:Seed set to 42\n"]}]},{"cell_type":"code","source":["# Comprobacion GPU\n","# Check that pyTorch is identifying the GPU\n","if torch.cuda.device_count() > 0:\n","    # If a GPU is available, print its name\n","    print(f'GPU detected. Currently using: \"{torch.cuda.get_device_name(0)}\"')\n","    # Set the device to GPU for accelerated computations\n","    device = torch.device(\"cuda\")\n","else:\n","    # If no GPU is available, inform the user to change the runtime type\n","    print('Currently using CPU. To utilize GPU acceleration, change the runtime type in the \\'runtime\\' tab.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qvjihweYTADL","executionInfo":{"status":"ok","timestamp":1718814955929,"user_tz":-120,"elapsed":266,"user":{"displayName":"Alvaro Carrillo","userId":"09121382412307725613"}},"outputId":"87b78912-de93-457b-a695-34b3bf17e347"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Currently using CPU. To utilize GPU acceleration, change the runtime type in the 'runtime' tab.\n"]}]},{"cell_type":"code","source":["# Conexion drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I3Ch2uWoTYOm","executionInfo":{"status":"ok","timestamp":1718814977876,"user_tz":-120,"elapsed":18331,"user":{"displayName":"Alvaro Carrillo","userId":"09121382412307725613"}},"outputId":"06c48bfb-4c25-46d3-ec7b-d960f5dbc04a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Lectura y Etiquetado de Datos"],"metadata":{"id":"JhzEpPNUT423"}},{"cell_type":"markdown","source":["### Task 4: Sexism Identification in Memes"],"metadata":{"id":"wozSRDmuTdNT"}},{"cell_type":"markdown","source":["Cargar los datos de entrenamiento y test"],"metadata":{"id":"ozc_SD-LZljs"}},{"cell_type":"code","source":["# En este caso, tenemos un único fichero de entrenamiento y un fichero independiente de test\n","train_data_path = '/content/drive/MyDrive/Dataset/Task 4/train_original.json'\n","test_data_path = '/content/drive/MyDrive/Dataset/Task 4/test_task4_hard.json'\n","#############################################################################################\n","\n","# Los transformamos en Dataframes\n","train_df_full = pd.read_json(train_data_path, orient='index')\n","test_df = pd.read_json(test_data_path, orient='index')"],"metadata":{"id":"uG_Thuz3T2Ag"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hard voting train_df"],"metadata":{"id":"OB8Nkj25Zt17"}},{"cell_type":"code","source":["columna_labels_task4_test = train_df_full['labels_task4']\n","\n","train_df_full['labels_task4'] = columna_labels_task4_test.apply(lambda x: max(set(x), key=x.count))\n","\n","train_df_full"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"zT4h-ZO7Uz33","executionInfo":{"status":"ok","timestamp":1718815053359,"user_tz":-120,"elapsed":305,"user":{"displayName":"Alvaro Carrillo","userId":"09121382412307725613"}},"outputId":"53aee925-ec57-454d-bf83-95e7c11ad352"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id_EXIST lang                                               text  \\\n","211158    211158   en  printf(\"\\n\"); printf(\". \\n\"); printf(\" *** \\n\"...   \n","110633    110633   es  MUJER EMPODERADA VSUPERIOR NO SE COMPARA CON U...   \n","211150    211150   en           Strong independent women Child support     \n","211445    211445   en  Four horsemen of turning straight guys gay The...   \n","211073    211073   en  HERE IS WHAT THE MOST BEAUTIFUL GIRL IN THE WO...   \n","...          ...  ...                                                ...   \n","210183    210183   en  Triggered Bitches Incoming in 5....4... 3...2....   \n","211555    211555   en  It's kind of slutty. OPIST DAILYFRIENDSCAPS [6...   \n","210824    210824   en  incels when that don't see people hurting wome...   \n","211380    211380   en  Make a transphobic or sexist meme because you ...   \n","210690    210690   en  LET ME GRAB THEM CHEEKS n I LOVE TO GRABBY mak...   \n","\n","               meme         path_memes  number_annotators  \\\n","211158  211158.jpeg  memes/211158.jpeg                  6   \n","110633  110633.jpeg  memes/110633.jpeg                  6   \n","211150  211150.jpeg  memes/211150.jpeg                  6   \n","211445  211445.jpeg  memes/211445.jpeg                  6   \n","211073  211073.jpeg  memes/211073.jpeg                  6   \n","...             ...                ...                ...   \n","210183  210183.jpeg  memes/210183.jpeg                  6   \n","211555  211555.jpeg  memes/211555.jpeg                  6   \n","210824  210824.jpeg  memes/210824.jpeg                  6   \n","211380  211380.jpeg  memes/211380.jpeg                  6   \n","210690  210690.jpeg  memes/210690.jpeg                  6   \n","\n","                                               annotators   gender_annotators  \\\n","211158  [Annotator_694, Annotator_695, Annotator_696, ...  [F, F, F, M, M, M]   \n","110633  [Annotator_139, Annotator_140, Annotator_141, ...  [F, F, F, M, M, M]   \n","211150  [Annotator_694, Annotator_695, Annotator_696, ...  [F, F, F, M, M, M]   \n","211445  [Annotator_758, Annotator_759, Annotator_760, ...  [F, F, F, M, M, M]   \n","211073  [Annotator_678, Annotator_679, Annotator_680, ...  [F, F, F, M, M, M]   \n","...                                                   ...                 ...   \n","210183  [Annotator_490, Annotator_491, Annotator_492, ...  [F, F, F, M, M, M]   \n","211555  [Annotator_781, Annotator_782, Annotator_783, ...  [F, F, F, M, M, M]   \n","210824  [Annotator_626, Annotator_627, Annotator_628, ...  [F, F, F, M, M, M]   \n","211380  [Annotator_746, Annotator_747, Annotator_748, ...  [F, F, F, M, M, M]   \n","210690  [Annotator_597, Annotator_598, Annotator_599, ...  [F, F, F, M, M, M]   \n","\n","                                age_annotators  \\\n","211158  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n","110633  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","211150  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n","211445  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n","211073  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n","...                                        ...   \n","210183  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n","211555  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n","210824  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n","211380  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n","210690  [18-22, 23-45, 46+, 18-22, 23-45, 46+]   \n","\n","                                   ethnicities_annotators  \\\n","211158  [Middle Eastern, White or Caucasian, White or ...   \n","110633  [Black or African American, White or Caucasian...   \n","211150  [Middle Eastern, White or Caucasian, White or ...   \n","211445  [White or Caucasian, White or Caucasian, White...   \n","211073  [other, Asian, White or Caucasian, White or Ca...   \n","...                                                   ...   \n","210183  [Hispano or Latino, Hispano or Latino, White o...   \n","211555  [White or Caucasian, Black or African American...   \n","210824  [White or Caucasian, Black or African American...   \n","211380  [White or Caucasian, Black or African American...   \n","210690  [White or Caucasian, White or Caucasian, White...   \n","\n","                                  study_levels_annotators  \\\n","211158  [High school degree or equivalent, Master’s de...   \n","110633  [Master’s degree, Bachelor’s degree, Bachelor’...   \n","211150  [High school degree or equivalent, Master’s de...   \n","211445  [Bachelor’s degree, Master’s degree, Bachelor’...   \n","211073  [High school degree or equivalent, Master’s de...   \n","...                                                   ...   \n","210183  [Bachelor’s degree, Master’s degree, High scho...   \n","211555  [High school degree or equivalent, Bachelor’s ...   \n","210824  [Bachelor’s degree, Bachelor’s degree, Bachelo...   \n","211380  [High school degree or equivalent, High school...   \n","210690  [Bachelor’s degree, Master’s degree, Master’s ...   \n","\n","                                     countries_annotators labels_task4  \\\n","211158  [Canada, France, Portugal, Estonia, Greece, Un...          YES   \n","110633  [Nigeria, Portugal, Spain, Spain, Portugal, Ch...          YES   \n","211150  [Canada, France, Portugal, Estonia, Greece, Un...          YES   \n","211445  [Portugal, Portugal, United Kingdom, Australia...          YES   \n","211073  [New Zealand, Viet Nam, United Kingdom, Hungar...          YES   \n","...                                                   ...          ...   \n","210183  [Mexico, Colombia, New Zealand, South Africa, ...          YES   \n","211555  [Australia, South Africa, United Kingdom, Sout...          YES   \n","210824  [Portugal, South Africa, United Kingdom, Polan...          YES   \n","211380  [Poland, South Africa, Spain, Germany, Germany...          YES   \n","210690  [Poland, Portugal, United Kingdom, Mexico, Pol...          YES   \n","\n","                                            labels_task5  \\\n","211158  [DIRECT, JUDGEMENTAL, DIRECT, JUDGEMENTAL, -, -]   \n","110633            [-, DIRECT, DIRECT, DIRECT, -, DIRECT]   \n","211150  [DIRECT, DIRECT, -, DIRECT, JUDGEMENTAL, DIRECT]   \n","211445       [-, JUDGEMENTAL, -, -, DIRECT, JUDGEMENTAL]   \n","211073  [JUDGEMENTAL, -, JUDGEMENTAL, DIRECT, -, DIRECT]   \n","...                                                  ...   \n","210183  [-, DIRECT, DIRECT, JUDGEMENTAL, JUDGEMENTAL, -]   \n","211555       [-, -, DIRECT, DIRECT, JUDGEMENTAL, DIRECT]   \n","210824  [JUDGEMENTAL, JUDGEMENTAL, JUDGEMENTAL, -, -, -]   \n","211380  [DIRECT, DIRECT, -, JUDGEMENTAL, -, JUDGEMENTAL]   \n","210690            [-, -, DIRECT, DIRECT, DIRECT, DIRECT]   \n","\n","                                             labels_task6          split  \n","211158  [[STEREOTYPING-DOMINANCE], [SEXUAL-VIOLENCE], ...  TRAIN-MEME_EN  \n","110633  [[-], [IDEOLOGICAL-INEQUALITY, STEREOTYPING-DO...  TRAIN-MEME_ES  \n","211150  [[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...  TRAIN-MEME_EN  \n","211445  [[-], [STEREOTYPING-DOMINANCE], [-], [-], [IDE...  TRAIN-MEME_EN  \n","211073  [[OBJECTIFICATION], [-], [UNKNOWN], [OBJECTIFI...  TRAIN-MEME_EN  \n","...                                                   ...            ...  \n","210183  [[-], [STEREOTYPING-DOMINANCE], [IDEOLOGICAL-I...  TRAIN-MEME_EN  \n","211555  [[-], [-], [STEREOTYPING-DOMINANCE], [OBJECTIF...  TRAIN-MEME_EN  \n","210824  [[OBJECTIFICATION], [MISOGYNY-NON-SEXUAL-VIOLE...  TRAIN-MEME_EN  \n","211380  [[IDEOLOGICAL-INEQUALITY], [IDEOLOGICAL-INEQUA...  TRAIN-MEME_EN  \n","210690  [[-], [-], [SEXUAL-VIOLENCE], [OBJECTIFICATION...  TRAIN-MEME_EN  \n","\n","[3235 rows x 16 columns]"],"text/html":["\n","  <div id=\"df-5d248289-59af-4d95-83e3-b1af443cf84a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_EXIST</th>\n","      <th>lang</th>\n","      <th>text</th>\n","      <th>meme</th>\n","      <th>path_memes</th>\n","      <th>number_annotators</th>\n","      <th>annotators</th>\n","      <th>gender_annotators</th>\n","      <th>age_annotators</th>\n","      <th>ethnicities_annotators</th>\n","      <th>study_levels_annotators</th>\n","      <th>countries_annotators</th>\n","      <th>labels_task4</th>\n","      <th>labels_task5</th>\n","      <th>labels_task6</th>\n","      <th>split</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>211158</th>\n","      <td>211158</td>\n","      <td>en</td>\n","      <td>printf(\"\\n\"); printf(\". \\n\"); printf(\" *** \\n\"...</td>\n","      <td>211158.jpeg</td>\n","      <td>memes/211158.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_694, Annotator_695, Annotator_696, ...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n","      <td>[Middle Eastern, White or Caucasian, White or ...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Canada, France, Portugal, Estonia, Greece, Un...</td>\n","      <td>YES</td>\n","      <td>[DIRECT, JUDGEMENTAL, DIRECT, JUDGEMENTAL, -, -]</td>\n","      <td>[[STEREOTYPING-DOMINANCE], [SEXUAL-VIOLENCE], ...</td>\n","      <td>TRAIN-MEME_EN</td>\n","    </tr>\n","    <tr>\n","      <th>110633</th>\n","      <td>110633</td>\n","      <td>es</td>\n","      <td>MUJER EMPODERADA VSUPERIOR NO SE COMPARA CON U...</td>\n","      <td>110633.jpeg</td>\n","      <td>memes/110633.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_139, Annotator_140, Annotator_141, ...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Black or African American, White or Caucasian...</td>\n","      <td>[Master’s degree, Bachelor’s degree, Bachelor’...</td>\n","      <td>[Nigeria, Portugal, Spain, Spain, Portugal, Ch...</td>\n","      <td>YES</td>\n","      <td>[-, DIRECT, DIRECT, DIRECT, -, DIRECT]</td>\n","      <td>[[-], [IDEOLOGICAL-INEQUALITY, STEREOTYPING-DO...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>211150</th>\n","      <td>211150</td>\n","      <td>en</td>\n","      <td>Strong independent women Child support</td>\n","      <td>211150.jpeg</td>\n","      <td>memes/211150.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_694, Annotator_695, Annotator_696, ...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n","      <td>[Middle Eastern, White or Caucasian, White or ...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Canada, France, Portugal, Estonia, Greece, Un...</td>\n","      <td>YES</td>\n","      <td>[DIRECT, DIRECT, -, DIRECT, JUDGEMENTAL, DIRECT]</td>\n","      <td>[[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...</td>\n","      <td>TRAIN-MEME_EN</td>\n","    </tr>\n","    <tr>\n","      <th>211445</th>\n","      <td>211445</td>\n","      <td>en</td>\n","      <td>Four horsemen of turning straight guys gay The...</td>\n","      <td>211445.jpeg</td>\n","      <td>memes/211445.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_758, Annotator_759, Annotator_760, ...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n","      <td>[White or Caucasian, White or Caucasian, White...</td>\n","      <td>[Bachelor’s degree, Master’s degree, Bachelor’...</td>\n","      <td>[Portugal, Portugal, United Kingdom, Australia...</td>\n","      <td>YES</td>\n","      <td>[-, JUDGEMENTAL, -, -, DIRECT, JUDGEMENTAL]</td>\n","      <td>[[-], [STEREOTYPING-DOMINANCE], [-], [-], [IDE...</td>\n","      <td>TRAIN-MEME_EN</td>\n","    </tr>\n","    <tr>\n","      <th>211073</th>\n","      <td>211073</td>\n","      <td>en</td>\n","      <td>HERE IS WHAT THE MOST BEAUTIFUL GIRL IN THE WO...</td>\n","      <td>211073.jpeg</td>\n","      <td>memes/211073.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_678, Annotator_679, Annotator_680, ...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n","      <td>[other, Asian, White or Caucasian, White or Ca...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[New Zealand, Viet Nam, United Kingdom, Hungar...</td>\n","      <td>YES</td>\n","      <td>[JUDGEMENTAL, -, JUDGEMENTAL, DIRECT, -, DIRECT]</td>\n","      <td>[[OBJECTIFICATION], [-], [UNKNOWN], [OBJECTIFI...</td>\n","      <td>TRAIN-MEME_EN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>210183</th>\n","      <td>210183</td>\n","      <td>en</td>\n","      <td>Triggered Bitches Incoming in 5....4... 3...2....</td>\n","      <td>210183.jpeg</td>\n","      <td>memes/210183.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_490, Annotator_491, Annotator_492, ...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, White o...</td>\n","      <td>[Bachelor’s degree, Master’s degree, High scho...</td>\n","      <td>[Mexico, Colombia, New Zealand, South Africa, ...</td>\n","      <td>YES</td>\n","      <td>[-, DIRECT, DIRECT, JUDGEMENTAL, JUDGEMENTAL, -]</td>\n","      <td>[[-], [STEREOTYPING-DOMINANCE], [IDEOLOGICAL-I...</td>\n","      <td>TRAIN-MEME_EN</td>\n","    </tr>\n","    <tr>\n","      <th>211555</th>\n","      <td>211555</td>\n","      <td>en</td>\n","      <td>It's kind of slutty. OPIST DAILYFRIENDSCAPS [6...</td>\n","      <td>211555.jpeg</td>\n","      <td>memes/211555.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_781, Annotator_782, Annotator_783, ...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n","      <td>[White or Caucasian, Black or African American...</td>\n","      <td>[High school degree or equivalent, Bachelor’s ...</td>\n","      <td>[Australia, South Africa, United Kingdom, Sout...</td>\n","      <td>YES</td>\n","      <td>[-, -, DIRECT, DIRECT, JUDGEMENTAL, DIRECT]</td>\n","      <td>[[-], [-], [STEREOTYPING-DOMINANCE], [OBJECTIF...</td>\n","      <td>TRAIN-MEME_EN</td>\n","    </tr>\n","    <tr>\n","      <th>210824</th>\n","      <td>210824</td>\n","      <td>en</td>\n","      <td>incels when that don't see people hurting wome...</td>\n","      <td>210824.jpeg</td>\n","      <td>memes/210824.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_626, Annotator_627, Annotator_628, ...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n","      <td>[White or Caucasian, Black or African American...</td>\n","      <td>[Bachelor’s degree, Bachelor’s degree, Bachelo...</td>\n","      <td>[Portugal, South Africa, United Kingdom, Polan...</td>\n","      <td>YES</td>\n","      <td>[JUDGEMENTAL, JUDGEMENTAL, JUDGEMENTAL, -, -, -]</td>\n","      <td>[[OBJECTIFICATION], [MISOGYNY-NON-SEXUAL-VIOLE...</td>\n","      <td>TRAIN-MEME_EN</td>\n","    </tr>\n","    <tr>\n","      <th>211380</th>\n","      <td>211380</td>\n","      <td>en</td>\n","      <td>Make a transphobic or sexist meme because you ...</td>\n","      <td>211380.jpeg</td>\n","      <td>memes/211380.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_746, Annotator_747, Annotator_748, ...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n","      <td>[White or Caucasian, Black or African American...</td>\n","      <td>[High school degree or equivalent, High school...</td>\n","      <td>[Poland, South Africa, Spain, Germany, Germany...</td>\n","      <td>YES</td>\n","      <td>[DIRECT, DIRECT, -, JUDGEMENTAL, -, JUDGEMENTAL]</td>\n","      <td>[[IDEOLOGICAL-INEQUALITY], [IDEOLOGICAL-INEQUA...</td>\n","      <td>TRAIN-MEME_EN</td>\n","    </tr>\n","    <tr>\n","      <th>210690</th>\n","      <td>210690</td>\n","      <td>en</td>\n","      <td>LET ME GRAB THEM CHEEKS n I LOVE TO GRABBY mak...</td>\n","      <td>210690.jpeg</td>\n","      <td>memes/210690.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_597, Annotator_598, Annotator_599, ...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 18-22, 23-45, 46+]</td>\n","      <td>[White or Caucasian, White or Caucasian, White...</td>\n","      <td>[Bachelor’s degree, Master’s degree, Master’s ...</td>\n","      <td>[Poland, Portugal, United Kingdom, Mexico, Pol...</td>\n","      <td>YES</td>\n","      <td>[-, -, DIRECT, DIRECT, DIRECT, DIRECT]</td>\n","      <td>[[-], [-], [SEXUAL-VIOLENCE], [OBJECTIFICATION...</td>\n","      <td>TRAIN-MEME_EN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3235 rows × 16 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d248289-59af-4d95-83e3-b1af443cf84a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5d248289-59af-4d95-83e3-b1af443cf84a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5d248289-59af-4d95-83e3-b1af443cf84a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1488e763-50e5-459e-82fb-cbd2cbe70cbc\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1488e763-50e5-459e-82fb-cbd2cbe70cbc')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1488e763-50e5-459e-82fb-cbd2cbe70cbc button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_df_full","summary":"{\n  \"name\": \"train_df_full\",\n  \"rows\": 3235,\n  \"fields\": [\n    {\n      \"column\": \"id_EXIST\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50003,\n        \"min\": 110001,\n        \"max\": 212010,\n        \"num_unique_values\": 3235,\n        \"samples\": [\n          212005,\n          110462,\n          111846\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"es\",\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3196,\n        \"samples\": [\n          \"Q imgflip.com version 8.938 WHERE THE BITCHES AT? 27307 RADIOLOGICAL SURVEY T 9928 GeCo \\\"DAT WAY\\\" 0:08:33  \",\n          \"imgflip.com LOOK INTO MY EYES CHALLENGE YOU FAILED, BRO  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"meme\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3235,\n        \"samples\": [\n          \"212005.jpeg\",\n          \"110462.jpeg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path_memes\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3235,\n        \"samples\": [\n          \"memes/212005.jpeg\",\n          \"memes/110462.jpeg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number_annotators\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotators\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender_annotators\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age_annotators\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ethnicities_annotators\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"study_levels_annotators\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"countries_annotators\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels_task4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"NO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels_task5\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels_task6\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"TRAIN-MEME_ES\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Balanceo de datos y divison train-valid"],"metadata":{"id":"_sigXyz7Z08H"}},{"cell_type":"code","source":["# Usamos estas variables para que el código sea más portable\n","nombre_etiqueta = 'labels_task4'\n","\n","# Muestra la distribucón original de las etiquetas\n","print(\"Distribución original - Train completo: \", train_df_full.value_counts(nombre_etiqueta))\n","\n","######## Undersampling manual ########################\n","# Para hacer un undersampling manual, se construye un dataframe para cada clase\n","# Por ejemplo, si se quiere hacer undersampling de la clase mayoritaria (0), se guarda\n","# en df_0 el número de filas de clase 0 que se quiere mantener y en df_1 todas las filas de clase 1\n","\n","# Contar cuántos son de cada clase y coger el minimo\n","num_class1 = (train_df_full[nombre_etiqueta] == 'YES').sum()\n","num_class2 = (train_df_full[nombre_etiqueta] == 'NO').sum()\n","min_size = min(num_class1,num_class2)\n","\n","# *******\n","df_0 = train_df_full[train_df_full[nombre_etiqueta]=='YES'].sample(n=min_size,random_state=42)\n","df_1 = train_df_full[train_df_full[nombre_etiqueta]=='NO'].sample(n=min_size,random_state=42)\n","# Se vuelve a construir el fichero de entrenamiento concatenando los 2 dataframes\n","train_df_full = pd.concat([df_0,df_1])\n","print(\"Distribución despues del undersampling: \", train_df_full.value_counts(nombre_etiqueta))\n","######################################################\n","# *******\n","\n","###### División train/valid/test #####################\n","# Si hay un único fichero\n","train_df, valid_df = train_test_split(train_df_full, test_size = 0.15, shuffle = True, stratify=train_df_full[[nombre_etiqueta]])\n","#valid_df, test_df = train_test_split(auxiliar_df, test_size = 0.3, shuffle = True, stratify=auxiliar_df[[nombre_etiqueta]])\n","\n","# Si hay ficheros de train y test independientes, sólo se hace división train/valid\n","train_df, valid_df = train_test_split(train_df_full, test_size = 0.15, shuffle = True, stratify=train_df_full[[nombre_etiqueta]])\n","######################################################\n","\n","\n","print(\"Ejemplos del conjunto completo de entrenamiento \", len(train_df_full))\n","print(\"Ejemplos usados para entrenar: \", len(train_df))\n","print(\"Ejemplos usados para validar: \", len(valid_df))\n","print(\"Ejemplos usados para test: \", len(test_df))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wC0ZrnZfYbCM","executionInfo":{"status":"ok","timestamp":1718815488470,"user_tz":-120,"elapsed":267,"user":{"displayName":"Alvaro Carrillo","userId":"09121382412307725613"}},"outputId":"d2ec5db3-ea5c-425e-d24e-3ce381efe091"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Distribución original - Train completo:  labels_task4\n","NO     1094\n","YES    1094\n","Name: count, dtype: int64\n","Distribución despues del undersampling:  labels_task4\n","NO     1094\n","YES    1094\n","Name: count, dtype: int64\n","Ejemplos del conjunto completo de entrenamiento  2188\n","Ejemplos usados para entrenar:  1859\n","Ejemplos usados para validar:  329\n","Ejemplos usados para test:  809\n"]}]},{"cell_type":"code","source":["# Para saber el número de filas de cada clase en cada división\n","print(\"distribución original - Train: \",train_df.value_counts(nombre_etiqueta))\n","print(\"distribución original - Valid: \",valid_df.value_counts(nombre_etiqueta))\n","print(\"distribución original - Test: \",test_df.value_counts(nombre_etiqueta))"],"metadata":{"id":"JVmPp5BJaF3u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Task 5: Source Intention in Memes"],"metadata":{"id":"FmAfLscnTu6d"}},{"cell_type":"markdown","source":["Cargar los datos de entrenamiento y test"],"metadata":{"id":"L3F9PCLOZOVm"}},{"cell_type":"code","source":["# En este caso, tenemos un único fichero de entrenamiento y un fichero independiente de test\n","train_data_path = '/content/drive/MyDrive/Dataset/Task 5/train_original.json'\n","test_data_path = '/content/drive/MyDrive/Dataset/Task 5/test_task5_hard.json'\n","#############################################################################################\n","\n","# Los transformamos en Dataframes\n","train_df_full = pd.read_json(train_data_path, orient='index')\n","test_df = pd.read_json(test_data_path, orient='index')"],"metadata":{"id":"hONVaypSUF-r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hard voting train_df"],"metadata":{"id":"-7fHXhPrZKdx"}},{"cell_type":"code","source":["train_df_full.reset_index(drop=True, inplace=True)\n","\n","# Cuenta la etiqueta más usada\n","def most_common_label(labels):\n","    counts = {}\n","    for label in labels:\n","        counts[label] = counts.get(label, 0) + 1\n","    return max(counts, key=counts.get)\n","\n","columna_labels_task5 = train_df_full['labels_task5']\n","mv = []\n","indices = []\n","i = 0\n","\n","for columna in columna_labels_task5:\n","    labels = []\n","    for data in columna:\n","        if data == 'DIRECT':\n","            labels.append('DIRECT')\n","        elif data == 'JUDGEMENTAL':\n","            labels.append('JUDGEMENTAL')\n","    if labels != []:\n","        mas_usado = most_common_label(labels)\n","        mv.append(mas_usado)\n","        indices.append(i)\n","    i += 1\n","\n","train_df_full = train_df_full.loc[indices]\n","train_df_full['labels_task5'] = mv\n","train_df_full"],"metadata":{"id":"ME5aMz2UUsUu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Balanceo de datos y divison train-valid"],"metadata":{"id":"e3ScgLhRY-AO"}},{"cell_type":"code","source":["# Usamos estas variables para que el código sea más portable\n","nombre_etiqueta = 'labels_task5'\n","\n","# Muestra la distribucón original de las etiquetas\n","print(\"Distribución original - Train completo: \", train_df_full.value_counts(nombre_etiqueta))\n","\n","######## Undersampling manual ########################\n","# Para hacer un undersampling manual, se construye un dataframe para cada clase\n","# Por ejemplo, si se quiere hacer undersampling de la clase mayoritaria (0), se guarda\n","# en df_0 el número de filas de clase 0 que se quiere mantener y en df_1 todas las filas de clase 1\n","\n","# Contar cuántos son de cada clase y coger el minimo\n","num_class1 = (train_df_full[nombre_etiqueta] == 'DIRECT').sum()\n","num_class2 = (train_df_full[nombre_etiqueta] == 'JUDGEMENTAL').sum()\n","min_size = min(num_class1,num_class2)\n","\n","# *******\n","df_0 = train_df_full[train_df_full[nombre_etiqueta]=='DIRECT'].sample(n=min_size,random_state=42)\n","df_1 = train_df_full[train_df_full[nombre_etiqueta]=='JUDGEMENTAL'].sample(n=min_size,random_state=42)\n","# Se vuelve a construir el fichero de entrenamiento concatenando los 2 dataframes\n","train_df_full = pd.concat([df_0,df_1])\n","print(\"Distribución despues del undersampling: \", train_df_full.value_counts(nombre_etiqueta))\n","######################################################\n","# *******\n","\n","###### División train/valid/test #####################\n","# Si hay un único fichero\n","train_df, valid_df = train_test_split(train_df_full, test_size = 0.15, shuffle = True, stratify=train_df_full[[nombre_etiqueta]])\n","#valid_df, test_df = train_test_split(auxiliar_df, test_size = 0.3, shuffle = True, stratify=auxiliar_df[[nombre_etiqueta]])\n","\n","# Si hay ficheros de train y test independientes, sólo se hace división train/valid\n","train_df, valid_df = train_test_split(train_df_full, test_size = 0.15, shuffle = True, stratify=train_df_full[[nombre_etiqueta]])\n","######################################################\n","\n","\n","print(\"Ejemplos del conjunto completo de entrenamiento \", len(train_df_full))\n","print(\"Ejemplos usados para entrenar: \", len(train_df))\n","print(\"Ejemplos usados para validar: \", len(valid_df))\n","print(\"Ejemplos usados para test: \", len(test_df))"],"metadata":{"id":"JexDD99cYybt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Para saber el número de filas de cada clase en cada división\n","print(\"distribución original - Train: \",train_df.value_counts(nombre_etiqueta))\n","print(\"distribución original - Valid: \",valid_df.value_counts(nombre_etiqueta))\n","print(\"distribución original - Test: \",test_df.value_counts(nombre_etiqueta))"],"metadata":{"id":"kW0nueYpaHj4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Preprocesado de Datos"],"metadata":{"id":"vJ0309b8aQWE"}},{"cell_type":"markdown","source":["Funciones de limpieza"],"metadata":{"id":"Xn3hA-KeaWbh"}},{"cell_type":"code","source":["import re\n","\n","def remove_links(tweet):\n","    \"\"\"Takes a string and removes web links from it\"\"\"\n","    tweet = re.sub(r'http\\S+', '', tweet)        # remove http links\n","    tweet = re.sub(r'bit.ly/\\S+', '', tweet)     # remove bitly links\n","    tweet = re.sub(r'\\[link\\]', '', tweet )      # remove [link]\n","    tweet = re.sub(r'\\[url\\]', '', tweet )       # remove [url]\n","    tweet = re.sub(r'pic.twitter\\S+','', tweet)\n","    return tweet\n","\n","def remove_users(tweet):\n","    \"\"\"Takes a string and removes retweet and @user information\"\"\"\n","    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet)  # remove re-tweet\n","    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet)      # remove tweeted at\n","    tweet = re.sub(r'\\[user\\]', '', tweet )                      # remove [user]\n","    return tweet\n","\n","def remove_hashtags(tweet):\n","    \"\"\"Takes a string and removes any hash tags\"\"\"\n","    tweet = re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet)      # remove hash tags\n","    return tweet\n","\n","def remove_av(tweet):\n","    \"\"\"Takes a string and removes AUDIO/VIDEO tags or labels\"\"\"\n","    tweet = re.sub('VIDEO:', '', tweet)  # remove 'VIDEO:' from start of tweet\n","    tweet = re.sub('AUDIO:', '', tweet)  # remove 'AUDIO:' from start of tweet\n","    return tweet\n","\n","def remove_emojis(tweet):\n","    emoj = re.compile(\"[\"\n","        u\"\\U00002700-\\U000027BF\"  # Dingbats\n","        u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n","        u\"\\U00002600-\\U000026FF\"  # Miscellaneous Symbols\n","        u\"\\U0001F300-\\U0001F5FF\"  # Miscellaneous Symbols And Pictographs\n","        u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n","        u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n","        u\"\\U00010000-\\U0010FFFF\"\n","        u\"\\U0001F680-\\U0001F6FF\"  # Transport and Map Symbols\n","        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","        u\"\\U00002702-\\U000027B0\"\n","        u\"\\U000024C2-\\U0001F251\"\n","        u\"\\U00002702-\\U000027B0\"\n","        u\"\\U000024C2-\\U0001F251\"\n","        u\"\\U0001f926-\\U0001f937\"\n","        u\"\\U00010000-\\U0010ffff\"\n","        u\"\\u2640-\\u2642\"\n","        u\"\\u2600-\\u2B55\"\n","        u\"\\ufe0f\"  # dingbats\n","\n","                      \"]+\", re.UNICODE)\n","    return re.sub(emoj, '', tweet)"],"metadata":{"id":"DGavid9uaaAv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Aplicación de las funciones"],"metadata":{"id":"1kUxr7Xdah9h"}},{"cell_type":"code","source":["campo_texto = 'text'\n","\n","train_df[campo_texto] = train_df[campo_texto].str.lower()\n","valid_df[campo_texto] = valid_df[campo_texto].str.lower()\n","test_df[campo_texto] = test_df[campo_texto].str.lower()\n","\n","#train_df[campo_texto] = train_df[campo_texto].apply(remove_links)\n","#valid_df[campo_texto] = valid_df[campo_texto].apply(remove_links)\n","#test_df[campo_texto] = test_df[campo_texto].apply(remove_links)\n","\n","#train_df[campo_texto] = train_df[campo_texto].apply(remove_users)\n","#valid_df[campo_texto] = valid_df[campo_texto].apply(remove_users)\n","#test_df[campo_texto] = test_df[campo_texto].apply(remove_users)\n","\n","#train_df[campo_texto] = train_df[campo_texto].apply(remove_hashtags)\n","#valid_df[campo_texto] = valid_df[campo_texto].apply(remove_hashtags)\n","#test_df[campo_texto] = test_df[campo_texto].apply(remove_hashtags)\n","\n","#train_df[campo_texto] = train_df[campo_texto].apply(remove_emojis)\n","#valid_df[campo_texto] = valid_df[campo_texto].apply(remove_emojis)\n","#test_df[campo_texto] = test_df[campo_texto].apply(remove_emojis)\n","\n","train_df"],"metadata":{"id":"IBUKNWhHamRC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Formateo y Etiquetado de los Datos"],"metadata":{"id":"2KLQvEtGawss"}},{"cell_type":"code","source":["# Se convierten los dataframes en objetos Datasets para que los acepten los Rransformers\n","train_dataset = Dataset.from_pandas(train_df)\n","valid_dataset = Dataset.from_pandas(valid_df)\n","test_dataset = Dataset.from_pandas(test_df)\n","\n","print(train_dataset, valid_dataset, test_dataset)"],"metadata":{"id":"cCCr3EKSa7Su"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Los objetos de tipo Dataset también se pueden mostrar en formato pandas\n","train_dataset.set_format(\"pandas\")\n","train_dataset[:]"],"metadata":{"id":"oPFlsfXJbAPi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reseteamos el formato para que evitar posibles fallos\n","train_dataset.reset_format()\n","valid_dataset.reset_format()"],"metadata":{"id":"UcsQG8cVbEBn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Task 4: Sexism Identification in Memes"],"metadata":{"id":"PHxtHUOZbLxa"}},{"cell_type":"code","source":["# Esta función toma un registro como entrada, que contiene una etiqueta llamada 'label'.\n","# Si el valor de esta etiqueta es 0, asigna 0 a la variable 'label'. Si el valor no es 0\n","# asigna 1 a 'label'. A continuación, la función devuelve un diccionario con la etiqueta modificada, llamado \"labels\"\n","\n","def set_labels(records):\n","  if records[nombre_etiqueta] == 'NO':\n","    label = 0\n","  else:\n","    label = 1\n","  return {'labels': label}"],"metadata":{"id":"VJhvOeD4bHke"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Task 5: Source Intention in Memes"],"metadata":{"id":"DGukks4KbT7s"}},{"cell_type":"code","source":["# Esta función toma un registro como entrada, que contiene una etiqueta llamada 'label'.\n","# Si el valor de esta etiqueta es 0, asigna 0 a la variable 'label'. Si el valor no es 0\n","# asigna 1 a 'label'. A continuación, la función devuelve un diccionario con la etiqueta modificada, llamado \"labels\"\n","\n","def set_labels(records):\n","  if records[nombre_etiqueta] == 'JUDGEMENTAL':\n","    label = 0\n","  else:\n","    label = 1\n","  return {'labels': label}"],"metadata":{"id":"2fWGf07dbXxS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Mapeado de la Función"],"metadata":{"id":"dIRbkpOCbt-P"}},{"cell_type":"code","source":["# Aplicamos la función a cada fila de los conjuntos de entrenamiento y validación\n","train_dataset = train_dataset.map(set_labels)\n","valid_dataset = valid_dataset.map(set_labels)\n","\n","print(train_dataset, valid_dataset)"],"metadata":{"id":"zM9ry-rAbdFR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reseteamos el formato para que no haya fallos\n","train_dataset.reset_format()\n","valid_dataset.reset_format()\n","test_dataset.reset_format()"],"metadata":{"id":"emkBsQtcb7DR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Selección de Modelo"],"metadata":{"id":"wOEspzUOcG1Y"}},{"cell_type":"code","source":["# Define the model checkpoint to be used for the task.\n","# Uncomment the desired model_checkpoint or replace it with your own.\n","\n","#model_checkpoint = 'xlm-roberta-base' # This model is one of the top-performing models in our experiments por the Spanish dataset\n","model_checkpoint = 'bert-base-multilingual-uncased'"],"metadata":{"id":"hlQsga38cM7o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tokenización"],"metadata":{"id":"Mml3DAL7cCBP"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_auth_token='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')"],"metadata":{"id":"d6kp1cUMcExv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Función para tokenizar un dataset\n","# La función tokenizer() hace la tokenización y devuelve los 'inputs_id' y los 'attention_mask'\n","\n","# Definir el método que se asignará al conjunto de datos para tokenizar los datos.\n","# Esta función toma un diccionario 'examples' como entrada, que contiene una clave llamada 'campo_texto'.\n","# La función usa el tokenizer para tokenizar el texto, lo trunca si excede la longitud máxima (MAX_LENGTH),\n","# y lo rellena para asegurar que todas las secuencias tienen la misma longitud.\n","\n","def tokenize_data(examples):\n","  return tokenizer(examples[campo_texto], truncation=True, max_length=MAX_LENGTH, padding=True)"],"metadata":{"id":"1UKnMvxWcZgs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MAX_LENGTH = 128\n","\n","# Construción de los ficheros codificados (encoded)\n","columns_train = train_dataset.column_names  # Coge todas las columnas\n","columns_valid = valid_dataset.column_names  # Coge todas las columnas\n","columns_train.remove(\"labels\") # Elimina la columna \"labels\"\n","columns_valid.remove(\"labels\") # Elimina la columna \"labels\"\n","\n","\n","# Hace la tokenización y elimina todas las columnas que no se necesitan\n","encoded_train_dataset = train_dataset.map(tokenize_data, batched=True, remove_columns=columns_train)\n","encoded_valid_dataset = valid_dataset.map(tokenize_data, batched=True, remove_columns=columns_valid)\n","encoded_train_dataset[100]"],"metadata":{"id":"-S2FHESGcdM2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.reset_index(drop=True, inplace=True)\n","train_df.loc[0]"],"metadata":{"id":"VKo7eK-cchLe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Definición de Métricas"],"metadata":{"id":"PnZnwW_5ckK0"}},{"cell_type":"code","source":["# Función para realizar distintas métricas en ejecución\n","\n","def compute_metrics(eval_pred):\n","\n","  ##############\n","  ## predictions son logits, que son tuplas de la forma [valor1, valor2]\n","  ## Por ejemplo [-1.5606991,  1.6122842] significa que ha predicho eso para un documento\n","  ## Eso es lo que pasa a la última capa del transformer (softmax si es binario)\n","  ## Por eso se utiliza el índice del valor máximo de la tupla, para decir que esa es la clase que predice\n","\n","  ## label_ids = [0, 1, 1, 0, 1]  # Etiquetas reales\n","  ## predictions = [\n","  ##  [0.8, 0.2],  # Predicciones para la primera instancia\n","  ##  [0.3, 0.7],  # Predicciones para la segunda instancia\n","  ##  [0.1, 0.9],  # Predicciones para la tercera instancia\n","  ##  [0.9, 0.1],  # Predicciones para la cuarta instancia\n","  ##  [0.4, 0.6],  # Predicciones para la quinta instancia\n","  ##           ]\n","\n","  ##############\n","\n","  labels = eval_pred.label_ids\n","  preds = eval_pred.predictions.argmax(-1)\n","\n","  # Compute precision, recall, F1-score, and support\n","  precision, recall, f1, _ = sk.metrics.precision_recall_fscore_support(labels, preds, average=\"macro\")\n","\n","  # Calculate F1-score for the minority class (label = 1)\n","  f1_minoritaria= f1_score(labels, preds, pos_label=1)\n","\n","  # Calculate F1-score for the majority class (label = 0)\n","  f1_mayoritaria = f1_score(labels, preds, pos_label=0)\n","\n","  # Calculate accuracy\n","  acc = sk.metrics.accuracy_score(labels, preds)\n","\n","  # Calculate Area Under the Curve (AUC)\n","  AUC = roc_auc_score(labels, preds)\n","\n","  # Calculate Precision-Recall Area Under the Curve (AUC)\n","  PREC_REC = average_precision_score(labels, preds)\n","\n","  return {\n","      'accuracy': acc,\n","      'f1': f1,\n","      'precision': precision,\n","      'recall': recall,\n","      'AUC': AUC,\n","      'f1_minoritaria': f1_minoritaria,\n","      'f1_mayoritaria': f1_mayoritaria,\n","      'PREC_REC': PREC_REC\n","  }"],"metadata":{"id":"kGyqeyKUcnEt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Entrenamiento del Modelo"],"metadata":{"id":"LY8NgExbcqHp"}},{"cell_type":"code","source":["# Se carga el modelo preentrenado\n","n_labels = 2\n","\n","# El uso de una función de inicialización facilita la repetición del entrenamiento\n","# Se puede usar la misma función de inicialización en diferentes ejecuciones del código o en configuraciones de entrenamiento diferentes\n","# Esto facilita la repetición del entrenamiento y la reproducibilidad, ya que se puede inicializar el modelo\n","# de la misma manera en cada ejecución.\n","\n","def model_init():\n","    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint,\n","                                                              num_labels = n_labels) #, return_dict = True )\n","                                                              # use_auth_token = 'token propio de HugginFace')"],"metadata":{"id":"Jef8CACGcwej"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Para saber el nombre del modelo\n","model_name = model_checkpoint.split(\"/\")[-1]\n","model_name"],"metadata":{"id":"C7Kq33kgcz2S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Fine-tuning"],"metadata":{"id":"HrXKRS2uc1xQ"}},{"cell_type":"code","source":["# Selección de hiperparámetros\n","BATCH_SIZE = 32\n","NUM_TRAIN_EPOCHS = 15\n","LEARNING_RATE = 3e-5\n","MAX_LENGTH = 128\n","WEIGHT_DECAY = 0.1"],"metadata":{"id":"5Pdcw_s4c4SQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se definen los parámetros del Trainer()\n","def maximum(a, b):\n","    if a >= b:\n","        return a\n","    else:\n","        return b\n","\n","\n","num_train_samples = int(len(encoded_train_dataset))\n","num_evaluation= int(len(encoded_valid_dataset))\n","\n","value = len(encoded_train_dataset) // (2 * BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","logging_steps = maximum(1, value)\n","\n","# logging_steps = max(1,len(encoded_train_dataset) // (2 * BATCH_SIZE * NUM_TRAIN_EPOCHS))\n","\n","optim = [\"adamw_hf\", \"adamw_torch\", \"adamw_apex_fused\", \"adafactor\", \"adamw_torch_xla\"]\n","\n","training_args = TrainingArguments(\n","    output_dir = 'results',\n","    num_train_epochs = NUM_TRAIN_EPOCHS,\n","    learning_rate = LEARNING_RATE,\n","    per_device_train_batch_size = BATCH_SIZE,\n","    per_device_eval_batch_size = BATCH_SIZE,\n","    load_best_model_at_end = True,\n","    metric_for_best_model = 'f1', # Cambiar la metrica por la que queremos ajustar\n","    #metric_for_best_model = 'eval_loss',\n","    weight_decay = WEIGHT_DECAY,\n","    evaluation_strategy = 'epoch',\n","    save_strategy = 'epoch',\n","    #logging_steps = logging_steps,\n","    save_total_limit = 3,\n","    optim = optim[1],\n","    push_to_hub = False\n",")"],"metadata":{"id":"VjWz_8yCc8pD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se crea el objeto Trainer()\n","trainer = Trainer(\n","    model_init = model_init,\n","    args = training_args,\n","    compute_metrics = compute_metrics,\n","    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)],\n","    train_dataset = encoded_train_dataset,\n","    eval_dataset = encoded_valid_dataset,\n","    tokenizer = tokenizer\n",")"],"metadata":{"id":"0JPOpYeRdKko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# A entrenar\n","trainer.train()"],"metadata":{"id":"tGoMkEN9dLpb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluación del Modelo"],"metadata":{"id":"juuMrKekdPiG"}},{"cell_type":"markdown","source":["Durante validación"],"metadata":{"id":"rhexgs3xdUQv"}},{"cell_type":"code","source":["eval = trainer.evaluate()\n","# Se pasa el resultado a Dataframe\n","dfeval = pd.DataFrame(list(eval.items()), columns = ['Nombre','Valor'])\n","dfeval"],"metadata":{"id":"umeFnhdBdWBr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se graba el modelo entrenado\n","trainer.save_model('/home/alvarocarrillo/TFG/Trabajo/Dataset/Modelos/Modelo_Roberta')"],"metadata":{"id":"Tsox9jymdgmO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluación con el test"],"metadata":{"id":"Z_zhXoMSdiJd"}},{"cell_type":"code","source":["# Lo pasamos a objeto dataset\n","test_dataset = Dataset.from_pandas(test_df)\n","test_dataset"],"metadata":{"id":"flW_6V50dko1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### SOLO CUANDO ESTAMOS EVALUANDO UN TEST ETIQUETADO\n","# Pasamos la etiqueta a label y le damos formato numérico\n","test_dataset = test_dataset.map(set_labels)  # La función set_labels ya se definió en el entrenamiento\n","test_dataset"],"metadata":{"id":"JQdXk8Amdotq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Predicciones"],"metadata":{"id":"0fCI2W_Ldu71"}},{"cell_type":"code","source":["# Se carga el modelo que se ha entrenado\n","model_path = '/home/alvarocarrillo/TFG/Trabajo/Dataset/Modelos/Modelo_Roberta'\n","\n","model = AutoModelForSequenceClassification.from_pretrained(model_path)"],"metadata":{"id":"k03vpBzbdt4V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predicción con pipeline\n","pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0)"],"metadata":{"id":"KtsWbiEEd1jc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hacemos las prediciones\n","def get_predictions(records):\n","  result = pipe(records[campo_texto], truncation=True)\n","  pred_label = result[0]['label']\n","  score_label = result[0]['score']\n","  #print(pred_label)\n","\n","  if pred_label == 'LABEL_0':\n","    pred_label = 0\n","  else:\n","    pred_label = 1\n","\n","  return {'pred_label': pred_label, 'score_label': score_label}"],"metadata":{"id":"eAzRW_1rd3hT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se hacen las predicciones sobre el conjunto de test\n","test_dataset_predicted = test_dataset.map(get_predictions)\n","test_dataset_predicted[0]"],"metadata":{"id":"viVwKU25d7cZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataset_predicted.set_format('pandas')\n","df_test = test_dataset_predicted[:]\n","df_test"],"metadata":{"id":"9GZpyYGCd-yE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Añadimos la función de evaluación\n","def compute_metrics(pred):\n","  labels = pred[0]\n","  preds = pred[1]\n","  precision, recall, f1, _ = sk.metrics.precision_recall_fscore_support(labels, preds, average=\"macro\")\n","  acc = sk.metrics.accuracy_score(labels, preds)\n","  AUC = roc_auc_score(labels, preds)\n","  PREC_REC = average_precision_score(labels, preds)\n","  return { 'accuracy': acc, 'f1': f1, 'precision': precision,\n","          'recall': recall, 'AUC': AUC, 'PREC_REC': PREC_REC }"],"metadata":{"id":"5ianP85heF-q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert the pandas series to python list to apply the compute_metric function\n","test_labels = df_test['labels'].values.tolist()\n","test_predictions = df_test['pred_label'].values.tolist()\n","eval_pred_test = [test_labels, test_predictions]"],"metadata":{"id":"reGkHFEQeHdJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p_test = compute_metrics(eval_pred_test)\n","dftest = pd.DataFrame([[key, p_test[key]] for key in p_test.keys()], columns=['Name', 'Value'])\n","dftest"],"metadata":{"id":"wkhcu5fjeN73"},"execution_count":null,"outputs":[]}]}